{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_C8FmHXHwA-"
      },
      "source": [
        "<h3>Stemming in NLTK</h3>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('hello')"
      ],
      "metadata": {
        "id": "WLTdcrEcJpvC",
        "outputId": "a9ace747-f26b-481c-aad2-5dc72c251312",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import spacy"
      ],
      "metadata": {
        "id": "oPPhYMa3Jr8n"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "i3qauYh4HwBG"
      },
      "outputs": [],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h_kuWAjGHwBM",
        "outputId": "447fff66-c17c-41bf-e80a-7a8a30741533",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating | eat\n",
            "eats | eat\n",
            "eat | eat\n",
            "ate | ate\n",
            "adjustable | adjust\n",
            "rafting | raft\n",
            "ability | abil\n",
            "meeting | meet\n"
          ]
        }
      ],
      "source": [
        "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n",
        "\n",
        "for word in words:\n",
        "    print(word, \"|\", stemmer.stem(word))\n",
        "# gorunduyu kimi sehv var, ate - ate kimi saxladi, belke de eat elemelidi, belke de ate kimi saxlamalidi. Cumlede de bunu basa dusmur.\n",
        "# ability - abil eledi. bu da sehvdi."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# basqa stemmer de var, burda da netice eynidir, ferqleri var yeqin ki, amma no need bilmeye, zaten nltk yaxsi islemir\n",
        "from nltk.stem import SnowballStemmer\n",
        "snowball = SnowballStemmer(language='english')"
      ],
      "metadata": {
        "id": "JIC7F4hBJ647"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rafting\", \"ability\", \"meeting\"]\n",
        "\n",
        "for word in words:\n",
        "    print(word, \"|\", snowball.stem(word))"
      ],
      "metadata": {
        "id": "Sc8wK-c5KByb",
        "outputId": "a82c7b59-d406-40c6-d723-4ae0817ef8a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating | eat\n",
            "eats | eat\n",
            "eat | eat\n",
            "ate | ate\n",
            "adjustable | adjust\n",
            "rafting | raft\n",
            "ability | abil\n",
            "meeting | meet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_s1KzMsHwBP"
      },
      "source": [
        "<h3>Lemmatization in Spacy</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oMS26AuHHwBQ"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "B53GzYBvHwBQ",
        "outputId": "ada03bd9-6b98-4492-c873-1c80b64fd551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating  |  eat\n",
            "eats  |  eat\n",
            "eat  |  eat\n",
            "ate  |  eat\n",
            "adjustable  |  adjustable\n",
            "rafting  |  raft\n",
            "ability  |  ability\n",
            "meeting  |  meeting\n",
            "better  |  well\n"
          ]
        }
      ],
      "source": [
        "# perfect\n",
        "# bu nlp model adlanir, sen pretrained model isledirsen\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "doc = nlp(\"eating eats eat ate adjustable rafting ability meeting better\")\n",
        "for token in doc:\n",
        "    print(token, \" | \", token.lemma_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SpaCy oz icerisinde map edir, hashing yeni, her soze bir reqem assign edir bir novu, unique olur bu her soz ucun, tekrarlanan sozlerde eyni olur.\n",
        "for token in doc:\n",
        "    print(token, \" | \", token.lemma_, \" | \", token.lemma)"
      ],
      "metadata": {
        "id": "774ihSGjMnJy",
        "outputId": "e39637ba-5ed1-4e07-84b9-c08dcfd55960",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eating  |  eat  |  9837207709914848172\n",
            "eats  |  eat  |  9837207709914848172\n",
            "eat  |  eat  |  9837207709914848172\n",
            "ate  |  eat  |  9837207709914848172\n",
            "adjustable  |  adjustable  |  6033511944150694480\n",
            "rafting  |  raft  |  7154368781129989833\n",
            "ability  |  ability  |  11565809527369121409\n",
            "meeting  |  meeting  |  14798207169164081740\n",
            "better  |  well  |  4525988469032889948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perfect\n",
        "doc = nlp(\"Mando talked for 3 hours although talking isn't his thing he became talkative\")\n",
        "for token in doc:\n",
        "    print(token, \" | \", token.lemma_)"
      ],
      "metadata": {
        "id": "pO79CyjML3vd",
        "outputId": "f34552ee-31ed-4a19-ff20-7fd30acc01f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mando  |  Mando\n",
            "talked  |  talk\n",
            "for  |  for\n",
            "3  |  3\n",
            "hours  |  hour\n",
            "although  |  although\n",
            "talking  |  talk\n",
            "is  |  be\n",
            "n't  |  not\n",
            "his  |  his\n",
            "thing  |  thing\n",
            "he  |  he\n",
            "became  |  become\n",
            "talkative  |  talkative\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zUCFGVwHwBS"
      },
      "source": [
        "<h3>Customizing lemmatizer</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "mgxFYDdeHwBT",
        "outputId": "2a7768c0-ba6f-48a0-c0cb-befaaebe2d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "nlp.pipe_names"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
        "for token in doc:\n",
        "    print(token.text, \"|\", token.lemma_)\n",
        "# Bro ve Brah -> brother'di eslinde, biz bunu bilirik, amma bunlar slang(jarqon) oldugu ucun, model bunu basa dusmur\n",
        "# ona gore de customize ederek, pre-trained modele ozun elave seyler oyredirsen"
      ],
      "metadata": {
        "id": "Pm6CHisiPfsr",
        "outputId": "e30f3035-1bb9-4d31-a793-a2bd85c1e01f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro | bro\n",
            ", | ,\n",
            "you | you\n",
            "wanna | wanna\n",
            "go | go\n",
            "? | ?\n",
            "Brah | Brah\n",
            ", | ,\n",
            "do | do\n",
            "n't | not\n",
            "say | say\n",
            "no | no\n",
            "! | !\n",
            "I | I\n",
            "am | be\n",
            "exhausted | exhaust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "scrolled": true,
        "id": "aXdAAh6rHwBX",
        "outputId": "316a824e-06b5-432e-d432-93e92cfda00c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bro | Brother\n",
            ", | ,\n",
            "you | you\n",
            "wanna | wanna\n",
            "go | go\n",
            "? | ?\n",
            "Brah | Brother\n",
            ", | ,\n",
            "do | do\n",
            "n't | not\n",
            "say | say\n",
            "no | no\n",
            "! | !\n",
            "I | I\n",
            "am | be\n",
            "exhausted | exhaust\n"
          ]
        }
      ],
      "source": [
        "# mueyyen componenti(stageni ve ya stepi) pipelineden goturmek ucun object olaraq bele yazmaq lazim\n",
        "ar = nlp.get_pipe('attribute_ruler')\n",
        "\n",
        "# attribute ruler'in icersine yenilik bele getirmek olur\n",
        "ar.add([[{\"TEXT\":\"Bro\"}],[{\"TEXT\":\"Brah\"}]],{\"LEMMA\":\"Brother\"})\n",
        "\n",
        "doc = nlp(\"Bro, you wanna go? Brah, don't say no! I am exhausted\")\n",
        "for token in doc:\n",
        "    print(token.text, \"|\", token.lemma_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hecne elave edilmedi component(stage, step) olaraq pipelineye, sadece attribute rulere elave qayda elave etdin :)\n",
        "nlp.pipe_names"
      ],
      "metadata": {
        "id": "t6Ah1aIqQA4_",
        "outputId": "813783ee-060a-491b-80e7-b24a92f33cc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ZO0qxA0DHwBZ",
        "outputId": "6423a892-97ab-40a6-a849-cd6309715ac4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Brah"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "doc[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JFvzu3O8HwBc",
        "outputId": "335c8c13-a06d-408f-c996-c05ca738c781",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Brother'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "doc[6].lemma_"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}