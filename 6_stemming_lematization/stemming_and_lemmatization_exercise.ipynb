{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-eWVL6QPtJqx"
      },
      "source": [
        "###                     **Stemming and Lemmatization: Exercises**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ig0FX6KjSKAL"
      },
      "source": [
        "- **Run this cell to import all necessary packages**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('hello')"
      ],
      "metadata": {
        "id": "ocO-zjfXSWuA",
        "outputId": "c4c6467e-0f56-4c03-ff5f-3f91459ee9be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hello\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fn0J_mWHtM57"
      },
      "outputs": [],
      "source": [
        "#let import necessary libraries and create the object\n",
        "\n",
        "#for nltk\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "#downloading all neccessary packages related to nltk\n",
        "nltk.download('all')\n",
        "\n",
        "\n",
        "#for spacy\n",
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCjMD77juhOm"
      },
      "source": [
        "**Exercise1:**\n",
        "- Convert these list of words into base form using Stemming and Lemmatization and observe the transformations\n",
        "- Write a short note on the words that have different base words using stemming and Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ytgw50jtM_h",
        "outputId": "a1583feb-5320-44c7-8252-24d73ecefd72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running  --->  run\n",
            "painting  --->  paint\n",
            "walking  --->  walk\n",
            "dressing  --->  dress\n",
            "likely  --->  like\n",
            "children  --->  children\n",
            "whom  --->  whom\n",
            "good  --->  good\n",
            "ate  --->  ate\n",
            "fishing  --->  fish\n"
          ]
        }
      ],
      "source": [
        "#using stemming in nltk\n",
        "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']\n",
        "\n",
        "for word in lst_words:\n",
        "  print(word, ' ---> ', stemmer.stem(word))\n",
        "# Bildiklerim bulardi:\n",
        "# likely -> ozu lemmadi, stemdi, rootdu -> deyismemelidir\n",
        "# whom -> oldugu kimi qalmalidi skfj\n",
        "# ate -> eat olmalidi\n",
        "# children -> child olmalidi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU7oPj0ftNCP",
        "outputId": "51377e2b-4b1b-40a1-c23e-f4ab70f77518"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "running  --->  run  --->  12767647472892411841\n",
            "painting  --->  paint  --->  16929211676819693673\n",
            "walking  --->  walk  --->  1674876016505392235\n",
            "dressing  --->  dress  --->  12815368344456308931\n",
            "likely  --->  likely  --->  6740298879949941214\n",
            "children  --->  child  --->  737253710922290542\n",
            "whom  --->  whom  --->  685434301945620124\n",
            "good  --->  good  --->  5711639017775284443\n",
            "ate  --->  eat  --->  9837207709914848172\n",
            "fishing  --->  fishing  --->  10959402079719336560\n"
          ]
        }
      ],
      "source": [
        "#using lemmatization in spacy\n",
        "\n",
        "doc = nlp(\"running painting walking dressing likely children whom good ate fishing\")\n",
        "\n",
        "for token in doc:\n",
        "  print(token, ' ---> ', token.lemma_, ' ---> ', token.lemma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLjsQGjVye5W"
      },
      "source": [
        "**Exercise2:**\n",
        "\n",
        "- convert the given text into it's base form using both stemming and lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0weT7a9tygnk"
      },
      "outputs": [],
      "source": [
        "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a\n",
        "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "JP29y7cjygqa",
        "outputId": "97a8414d-9eb1-4194-8a86-ab552dfe0462"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['latha', 'is', 'veri', 'multi', 'talent', 'girl.sh', 'is', 'good', 'at', 'mani', 'skill', 'like', 'danc', ',', 'run', ',', 'sing', ',', 'playing.sh', 'also', 'like', 'eat', 'pav', 'bhagi', '.', 'she', 'ha', 'a', 'habit', 'of', 'fish', 'and', 'swim', 'too.besid', 'all', 'thi', ',', 'she', 'is', 'a', 'wonder', 'at', 'cook', 'too', '.']\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'latha, is, veri, multi, talent, girl.sh, is, good, at, mani, skill, like, danc, ,, run, ,, sing, ,, playing.sh, also, like, eat, pav, bhagi, ., she, ha, a, habit, of, fish, and, swim, too.besid, all, thi, ,, she, is, a, wonder, at, cook, too, .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "#using stemming in nltk\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#step1: Word tokenizing\n",
        "words_list = word_tokenize(text)\n",
        "\n",
        "\n",
        "#step2: getting the base form for each token using stemmer\n",
        "words_list = [stemmer.stem(word) for word in words_list]\n",
        "print(words_list, end='\\n\\n')\n",
        "\n",
        "\n",
        "#step3: joining all words in a list into string using 'join()'\n",
        "', '.join(words_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "for i in sent_tokenize(text):\n",
        "  print(i, end='\\n\\n')"
      ],
      "metadata": {
        "id": "5AInirYIY5YL",
        "outputId": "8bc4db72-367e-4c1e-f0e1-2b2aa3f9a552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi.\n",
            "\n",
            "she has a \n",
            "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using stemming in nltk\n",
        "\n",
        "#step1: Word tokenizing\n",
        "all_word_tokens = nltk.word_tokenize(text)\n",
        "\n",
        "\n",
        "#step2: getting the base form for each token using stemmer\n",
        "all_base_words = []\n",
        "\n",
        "for token in all_word_tokens:\n",
        "  base_form = stemmer.stem(token)\n",
        "  all_base_words.append(base_form)\n",
        "\n",
        "\n",
        "#step3: joining all words in a list into string using 'join()'\n",
        "final_base_text = ' '.join(all_base_words)\n",
        "print(final_base_text)"
      ],
      "metadata": {
        "id": "7reLYZu_b_mk",
        "outputId": "e7832247-b46c-424a-ee23-259804f0f453",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "latha is veri multi talent girl.sh is good at mani skill like danc , run , sing , playing.sh also like eat pav bhagi . she ha a habit of fish and swim too.besid all thi , she is a wonder at cook too .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hysIhJuxyg0B",
        "outputId": "1dd5ddc4-cd9f-43fc-feee-2bc58c693f0d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Latha be very multi talented girl.', 'she be good at many skill like dancing, running, singing, play.', 'she also like eat Pav Bhagi.', 'she have a \\nhabit of fishing and swim too.', 'besides all this, she be a wonderful at cook too.']\n",
            "\n",
            "Latha be very multi talented girl.she be good at many skill like dancing, running, singing, play.she also like eat Pav Bhagi.she have a \n",
            "habit of fishing and swim too.besides all this, she be a wonderful at cook too.\n",
            "\n",
            "\n",
            "\n",
            "['Latha', 'be', 'very', 'multi', 'talented', 'girl', '.', 'she', 'be', 'good', 'at', 'many', 'skill', 'like', 'dancing', ',', 'running', ',', 'singing', ',', 'play', '.', 'she', 'also', 'like', 'eat', 'Pav', 'Bhagi', '.', 'she', 'have', 'a', '\\n', 'habit', 'of', 'fishing', 'and', 'swim', 'too', '.', 'besides', 'all', 'this', ',', 'she', 'be', 'a', 'wonderful', 'at', 'cook', 'too', '.', '\\n']\n",
            "\n",
            "Latha, be, very, multi, talented, girl, ., she, be, good, at, many, skill, like, dancing, ,, running, ,, singing, ,, play, ., she, also, like, eat, Pav, Bhagi, ., she, have, a, \n",
            ", habit, of, fishing, and, swim, too, ., besides, all, this, ,, she, be, a, wonderful, at, cook, too, ., \n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#using lemmatisation in spacy\n",
        "\n",
        "\n",
        "#step1: Creating the object for the given text\n",
        "doc = nlp(text)\n",
        "\n",
        "\n",
        "#step2: getting the base form for each token using spacy 'lemma_'\n",
        "l = [token.lemma_ for token in [sentence for sentence in doc.sents]]\n",
        "print(l, end='\\n\\n')\n",
        "print(''.join(l), end='\\n\\n\\n\\n')\n",
        "\n",
        "li = []\n",
        "for sentence in doc.sents:\n",
        "  for token in sentence:\n",
        "    li.append(token.lemma_)\n",
        "print(li, end='\\n\\n')\n",
        "\n",
        "#step3: joining all words in a list into string using 'join()'\n",
        "print(', '.join(li), end='\\n\\n')\n",
        "\n",
        "# iki usulla hell etdim. sentence kimi rootlari yigib, sonra o sentencelere birlesdirmek\n",
        "# basqa usul da, istedildiyi kimi, sozleri dene dene yigdim."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using lemmatisation in spacy\n",
        "\n",
        "\n",
        "#step1: Creating the object for the given text\n",
        "doc = nlp(text)\n",
        "all_base_words = []\n",
        "\n",
        "#step2: getting the base form for each token using spacy 'lemma_'\n",
        "for token in doc:\n",
        "  base_word =  token.lemma_\n",
        "  all_base_words.append(base_word)\n",
        "\n",
        "\n",
        "#step3: joining all words in a list into string using 'join()'\n",
        "final_base_text = ' '.join(all_base_words)\n",
        "print(final_base_text)"
      ],
      "metadata": {
        "id": "IjDmC3r3cFu0",
        "outputId": "68ae06d4-01fe-4ea3-a657-2fd19be54977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latha be very multi talented girl . she be good at many skill like dancing , running , singing , play . she also like eat Pav Bhagi . she have a \n",
            " habit of fishing and swim too . besides all this , she be a wonderful at cook too . \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcrKmTQ0SKAR"
      },
      "source": [
        "## [**Solution**](./stemming_and_lemmatization_solutions.ipynb)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Stemming and Lemmatization.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}